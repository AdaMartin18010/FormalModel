# TaskExpertæ¨¡å‹å®ç°ç¤ºä¾‹ / TaskExpert Model Implementation Example

## æ¦‚è¿° / Overview

æœ¬æ–‡æ¡£å±•ç¤ºäº†2025å¹´æœ€æ–°TaskExpertæ¨¡å‹çš„å®Œæ•´å®ç°ç¤ºä¾‹ï¼Œè¯¥æ¨¡å‹å¼•å…¥ä¸“å®¶ç½‘ç»œç»„å°†ä¸»å¹²ç‰¹å¾åˆ†è§£ä¸ºä»»åŠ¡é€šç”¨ç‰¹å¾ï¼Œå¹¶é€šè¿‡åŠ¨æ€ä»»åŠ¡ç‰¹å®šé—¨æ§ç½‘ç»œè§£ç ä»»åŠ¡ç‰¹å®šç‰¹å¾ï¼Œæ˜¾è‘—æå‡å¤šä»»åŠ¡å­¦ä¹ æ€§èƒ½ã€‚

## ğŸ¯ TaskExpertæ¨¡å‹åŸç† / TaskExpert Model Principles

### æ ¸å¿ƒæ€æƒ³ / Core Concept

TaskExpertæ¨¡å‹é€šè¿‡å¼•å…¥ä¸€ç»„ä¸“å®¶ç½‘ç»œï¼Œå°†ä¸»å¹²ç‰¹å¾åˆ†è§£ä¸ºå¤šä¸ªä»£è¡¨æ€§ä»»åŠ¡é€šç”¨ç‰¹å¾ï¼Œå¹¶é€šè¿‡åŠ¨æ€ä»»åŠ¡ç‰¹å®šé—¨æ§ç½‘ç»œè§£ç ä»»åŠ¡ç‰¹å®šç‰¹å¾ï¼Œå®ç°é«˜æ•ˆçš„å¤šä»»åŠ¡å­¦ä¹ ã€‚

### æ•°å­¦å½¢å¼åŒ– / Mathematical Formulation

#### 1. ä¸“å®¶ç½‘ç»œæ¶æ„ / Expert Network Architecture

**ä¸“å®¶ç½‘ç»œé›†åˆ**:
$$E = \{E_1, E_2, \ldots, E_K\}$$

**ä¸»å¹²ç‰¹å¾**:
$$h = f_\theta(x) \in \mathbb{R}^d$$

**ä¸“å®¶ç‰¹å¾åˆ†è§£**:
$$e_i = E_i(h) \in \mathbb{R}^{d_e}, \quad i = 1, 2, \ldots, K$$

**ä»»åŠ¡é€šç”¨ç‰¹å¾**:
$$g = \text{Concat}(e_1, e_2, \ldots, e_K) \in \mathbb{R}^{K \cdot d_e}$$

#### 2. åŠ¨æ€é—¨æ§ç½‘ç»œ / Dynamic Gating Network

**ä»»åŠ¡ç‰¹å®šé—¨æ§**:
$$G_k: \mathbb{R}^{K \cdot d_e} \rightarrow \mathbb{R}^K$$

**é—¨æ§æƒé‡**:
$$w_k = \text{softmax}(G_k(g)) \in \mathbb{R}^K$$

**ä»»åŠ¡ç‰¹å®šç‰¹å¾**:
$$f_k = \sum_{i=1}^K w_{k,i} \cdot e_i$$

#### 3. ä»»åŠ¡é¢„æµ‹ / Task Prediction

**ä»»åŠ¡ç‰¹å®šé¢„æµ‹å¤´**:
$$T_k: \mathbb{R}^{d_e} \rightarrow \mathbb{R}^{d_k}$$

**æœ€ç»ˆé¢„æµ‹**:
$$\hat{y}_k = T_k(f_k)$$

## ğŸ”§ ç®—æ³•å®ç° / Algorithm Implementation

### Pythonå®ç° / Python Implementation

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Dict, Tuple, Optional
import math
from dataclasses import dataclass

@dataclass
class TaskExpertConfig:
    """TaskExperté…ç½®ç±»"""
    input_dim: int = 784
    backbone_dim: int = 512
    expert_dim: int = 128
    num_experts: int = 8
    num_tasks: int = 5
    task_output_dims: List[int] = None
    dropout: float = 0.1
    learning_rate: float = 1e-3
    weight_decay: float = 1e-4
    
    def __post_init__(self):
        if self.task_output_dims is None:
            self.task_output_dims = [10] * self.num_tasks

class BackboneNetwork(nn.Module):
    """ä¸»å¹²ç½‘ç»œ"""
    def __init__(self, input_dim: int, backbone_dim: int):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, backbone_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(backbone_dim * 2, backbone_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(backbone_dim, backbone_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

class ExpertNetwork(nn.Module):
    """ä¸“å®¶ç½‘ç»œ"""
    def __init__(self, backbone_dim: int, expert_dim: int):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(backbone_dim, expert_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(expert_dim * 2, expert_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(expert_dim, expert_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

class DynamicGatingNetwork(nn.Module):
    """åŠ¨æ€é—¨æ§ç½‘ç»œ"""
    def __init__(self, expert_dim: int, num_experts: int):
        super().__init__()
        self.num_experts = num_experts
        self.gate = nn.Sequential(
            nn.Linear(expert_dim * num_experts, expert_dim),
            nn.ReLU(),
            nn.Linear(expert_dim, num_experts),
            nn.Softmax(dim=-1)
        )
        
    def forward(self, expert_features: torch.Tensor) -> torch.Tensor:
        """
        Args:
            expert_features: [batch_size, num_experts, expert_dim]
        Returns:
            gate_weights: [batch_size, num_experts]
        """
        batch_size, num_experts, expert_dim = expert_features.shape
        
        # å±•å¹³ä¸“å®¶ç‰¹å¾
        flattened = expert_features.view(batch_size, -1)
        
        # è®¡ç®—é—¨æ§æƒé‡
        gate_weights = self.gate(flattened)
        
        return gate_weights

class TaskSpecificHead(nn.Module):
    """ä»»åŠ¡ç‰¹å®šé¢„æµ‹å¤´"""
    def __init__(self, expert_dim: int, output_dim: int):
        super().__init__()
        self.head = nn.Sequential(
            nn.Linear(expert_dim, expert_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(expert_dim // 2, output_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.head(x)

class TaskExpertModel(nn.Module):
    """TaskExpertä¸»æ¨¡å‹"""
    def __init__(self, config: TaskExpertConfig):
        super().__init__()
        self.config = config
        
        # ä¸»å¹²ç½‘ç»œ
        self.backbone = BackboneNetwork(config.input_dim, config.backbone_dim)
        
        # ä¸“å®¶ç½‘ç»œ
        self.experts = nn.ModuleList([
            ExpertNetwork(config.backbone_dim, config.expert_dim)
            for _ in range(config.num_experts)
        ])
        
        # åŠ¨æ€é—¨æ§ç½‘ç»œï¼ˆæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªï¼‰
        self.gating_networks = nn.ModuleList([
            DynamicGatingNetwork(config.expert_dim, config.num_experts)
            for _ in range(config.num_tasks)
        ])
        
        # ä»»åŠ¡ç‰¹å®šé¢„æµ‹å¤´
        self.task_heads = nn.ModuleList([
            TaskSpecificHead(config.expert_dim, config.task_output_dims[i])
            for i in range(config.num_tasks)
        ])
        
        # ç‰¹å¾èåˆå±‚
        self.feature_fusion = nn.Sequential(
            nn.Linear(config.expert_dim * config.num_experts, config.expert_dim),
            nn.ReLU(),
            nn.Dropout(config.dropout)
        )
        
    def forward(self, x: torch.Tensor, task_id: int) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è¾“å…¥æ•°æ® [batch_size, input_dim]
            task_id: ä»»åŠ¡ID
        Returns:
            prediction: ä»»åŠ¡é¢„æµ‹ç»“æœ
            aux_info: è¾…åŠ©ä¿¡æ¯ï¼ˆé—¨æ§æƒé‡ã€ä¸“å®¶ç‰¹å¾ç­‰ï¼‰
        """
        batch_size = x.size(0)
        
        # 1. ä¸»å¹²ç‰¹å¾æå–
        backbone_features = self.backbone(x)  # [batch_size, backbone_dim]
        
        # 2. ä¸“å®¶ç‰¹å¾åˆ†è§£
        expert_features = []
        for expert in self.experts:
            expert_feat = expert(backbone_features)  # [batch_size, expert_dim]
            expert_features.append(expert_feat)
        
        expert_features = torch.stack(expert_features, dim=1)  # [batch_size, num_experts, expert_dim]
        
        # 3. åŠ¨æ€é—¨æ§
        gate_weights = self.gating_networks[task_id](expert_features)  # [batch_size, num_experts]
        
        # 4. ä»»åŠ¡ç‰¹å®šç‰¹å¾èåˆ
        task_specific_features = torch.sum(
            expert_features * gate_weights.unsqueeze(-1), dim=1
        )  # [batch_size, expert_dim]
        
        # 5. ä»»åŠ¡é¢„æµ‹
        prediction = self.task_heads[task_id](task_specific_features)
        
        # è¾…åŠ©ä¿¡æ¯
        aux_info = {
            'backbone_features': backbone_features,
            'expert_features': expert_features,
            'gate_weights': gate_weights,
            'task_specific_features': task_specific_features
        }
        
        return prediction, aux_info
    
    def get_expert_utilization(self, x: torch.Tensor, task_ids: List[int]) -> Dict[str, float]:
        """è®¡ç®—ä¸“å®¶åˆ©ç”¨ç‡"""
        utilizations = {}
        
        for task_id in task_ids:
            with torch.no_grad():
                _, aux_info = self.forward(x, task_id)
                gate_weights = aux_info['gate_weights']
                
                # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡åˆ©ç”¨ç‡
                expert_utils = gate_weights.mean(dim=0).cpu().numpy()
                utilizations[f'task_{task_id}'] = expert_utils.tolist()
        
        return utilizations

class TaskExpertTrainer:
    """TaskExpertè®­ç»ƒå™¨"""
    def __init__(self, model: TaskExpertModel, config: TaskExpertConfig):
        self.model = model
        self.config = config
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.CrossEntropyLoss()
        
        # ä¸“å®¶å¤šæ ·æ€§æŸå¤±æƒé‡
        self.diversity_weight = 0.1
        
    def compute_diversity_loss(self, gate_weights: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—ä¸“å®¶å¤šæ ·æ€§æŸå¤±"""
        # è®¡ç®—é—¨æ§æƒé‡çš„ç†µï¼Œé¼“åŠ±ä¸“å®¶å¤šæ ·æ€§
        entropy = -torch.sum(gate_weights * torch.log(gate_weights + 1e-8), dim=-1)
        diversity_loss = -entropy.mean()  # è´Ÿç†µï¼Œé¼“åŠ±å¤šæ ·æ€§
        return diversity_loss
    
    def compute_expert_balance_loss(self, gate_weights: torch.Tensor) -> torch.Tensor:
        """è®¡ç®—ä¸“å®¶å¹³è¡¡æŸå¤±"""
        # è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡åˆ©ç”¨ç‡
        expert_usage = gate_weights.mean(dim=0)  # [num_experts]
        
        # è®¡ç®—åˆ©ç”¨ç‡çš„æ ‡å‡†å·®ï¼Œé¼“åŠ±å¹³è¡¡ä½¿ç”¨
        balance_loss = torch.std(expert_usage)
        return balance_loss
    
    def train_step(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """å•æ­¥è®­ç»ƒ"""
        self.model.train()
        self.optimizer.zero_grad()
        
        total_loss = 0.0
        task_losses = []
        diversity_losses = []
        balance_losses = []
        
        # å¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œè®­ç»ƒ
        for task_id in range(self.config.num_tasks):
            x = batch['inputs'][task_id]
            y = batch['targets'][task_id]
            
            # å‰å‘ä¼ æ’­
            prediction, aux_info = self.model(x, task_id)
            
            # ä»»åŠ¡æŸå¤±
            task_loss = self.criterion(prediction, y)
            task_losses.append(task_loss.item())
            total_loss += task_loss
            
            # ä¸“å®¶å¤šæ ·æ€§æŸå¤±
            gate_weights = aux_info['gate_weights']
            diversity_loss = self.compute_diversity_loss(gate_weights)
            diversity_losses.append(diversity_loss.item())
            total_loss += self.diversity_weight * diversity_loss
            
            # ä¸“å®¶å¹³è¡¡æŸå¤±
            balance_loss = self.compute_expert_balance_loss(gate_weights)
            balance_losses.append(balance_loss.item())
            total_loss += 0.05 * balance_loss
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
        
        self.optimizer.step()
        
        return {
            'total_loss': total_loss.item(),
            'task_losses': task_losses,
            'diversity_losses': diversity_losses,
            'balance_losses': balance_losses,
            'avg_task_loss': np.mean(task_losses),
            'avg_diversity_loss': np.mean(diversity_losses),
            'avg_balance_loss': np.mean(balance_losses)
        }
    
    def evaluate(self, batch: Dict[str, torch.Tensor]) -> Dict[str, float]:
        """è¯„ä¼°"""
        self.model.eval()
        
        total_accuracy = 0.0
        task_accuracies = []
        
        with torch.no_grad():
            for task_id in range(self.config.num_tasks):
                x = batch['inputs'][task_id]
                y = batch['targets'][task_id]
                
                prediction, _ = self.model(x, task_id)
                
                # è®¡ç®—å‡†ç¡®ç‡
                pred_labels = torch.argmax(prediction, dim=1)
                accuracy = (pred_labels == y).float().mean().item()
                task_accuracies.append(accuracy)
                total_accuracy += accuracy
        
        return {
            'total_accuracy': total_accuracy / self.config.num_tasks,
            'task_accuracies': task_accuracies
        }

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # é…ç½®
    config = TaskExpertConfig(
        input_dim=784,
        backbone_dim=512,
        expert_dim=128,
        num_experts=8,
        num_tasks=5,
        task_output_dims=[10, 5, 3, 7, 4],
        learning_rate=1e-3
    )
    
    # åˆ›å»ºæ¨¡å‹
    model = TaskExpertModel(config)
    trainer = TaskExpertTrainer(model, config)
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 32
    batch = {
        'inputs': [
            torch.randn(batch_size, config.input_dim) for _ in range(config.num_tasks)
        ],
        'targets': [
            torch.randint(0, config.task_output_dims[i], (batch_size,))
            for i in range(config.num_tasks)
        ]
    }
    
    # è®­ç»ƒ
    for epoch in range(10):
        loss_info = trainer.train_step(batch)
        print(f"Epoch {epoch}: {loss_info}")
    
    # è¯„ä¼°
    eval_info = trainer.evaluate(batch)
    print(f"Evaluation: {eval_info}")
    
    # ä¸“å®¶åˆ©ç”¨ç‡åˆ†æ
    task_ids = list(range(config.num_tasks))
    utilizations = model.get_expert_utilization(batch['inputs'][0], task_ids)
    print(f"Expert Utilizations: {utilizations}")

if __name__ == "__main__":
    main()
```

### Rustå®ç° / Rust Implementation

```rust
use ndarray::{Array2, Array3, Array4, Axis};
use ndarray_rand::RandomExt;
use rand::distributions::Uniform;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskExpertConfig {
    pub input_dim: usize,
    pub backbone_dim: usize,
    pub expert_dim: usize,
    pub num_experts: usize,
    pub num_tasks: usize,
    pub task_output_dims: Vec<usize>,
    pub dropout: f64,
    pub learning_rate: f64,
    pub weight_decay: f64,
}

impl Default for TaskExpertConfig {
    fn default() -> Self {
        Self {
            input_dim: 784,
            backbone_dim: 512,
            expert_dim: 128,
            num_experts: 8,
            num_tasks: 5,
            task_output_dims: vec![10, 5, 3, 7, 4],
            dropout: 0.1,
            learning_rate: 1e-3,
            weight_decay: 1e-4,
        }
    }
}

#[derive(Debug, Clone)]
pub struct BackboneNetwork {
    pub weights: Vec<Array2<f64>>,
    pub biases: Vec<Array1<f64>>,
    pub input_dim: usize,
    pub output_dim: usize,
}

impl BackboneNetwork {
    pub fn new(input_dim: usize, backbone_dim: usize) -> Self {
        let mut weights = Vec::new();
        let mut biases = Vec::new();
        
        // ç¬¬ä¸€å±‚: input_dim -> backbone_dim * 2
        weights.push(Array2::random((input_dim, backbone_dim * 2), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(backbone_dim * 2));
        
        // ç¬¬äºŒå±‚: backbone_dim * 2 -> backbone_dim
        weights.push(Array2::random((backbone_dim * 2, backbone_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(backbone_dim));
        
        // ç¬¬ä¸‰å±‚: backbone_dim -> backbone_dim
        weights.push(Array2::random((backbone_dim, backbone_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(backbone_dim));
        
        Self {
            weights,
            biases,
            input_dim,
            output_dim: backbone_dim,
        }
    }
    
    pub fn forward(&self, x: &Array2<f64>) -> Array2<f64> {
        let mut output = x.clone();
        
        for (weight, bias) in self.weights.iter().zip(self.biases.iter()) {
            output = output.dot(weight) + bias;
            // ReLUæ¿€æ´»
            output.mapv_inplace(|v| if v > 0.0 { v } else { 0.0 });
        }
        
        output
    }
}

#[derive(Debug, Clone)]
pub struct ExpertNetwork {
    pub weights: Vec<Array2<f64>>,
    pub biases: Vec<Array1<f64>>,
    pub input_dim: usize,
    pub output_dim: usize,
}

impl ExpertNetwork {
    pub fn new(backbone_dim: usize, expert_dim: usize) -> Self {
        let mut weights = Vec::new();
        let mut biases = Vec::new();
        
        // ç¬¬ä¸€å±‚: backbone_dim -> expert_dim * 2
        weights.push(Array2::random((backbone_dim, expert_dim * 2), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(expert_dim * 2));
        
        // ç¬¬äºŒå±‚: expert_dim * 2 -> expert_dim
        weights.push(Array2::random((expert_dim * 2, expert_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(expert_dim));
        
        // ç¬¬ä¸‰å±‚: expert_dim -> expert_dim
        weights.push(Array2::random((expert_dim, expert_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(expert_dim));
        
        Self {
            weights,
            biases,
            input_dim: backbone_dim,
            output_dim: expert_dim,
        }
    }
    
    pub fn forward(&self, x: &Array2<f64>) -> Array2<f64> {
        let mut output = x.clone();
        
        for (weight, bias) in self.weights.iter().zip(self.biases.iter()) {
            output = output.dot(weight) + bias;
            // ReLUæ¿€æ´»
            output.mapv_inplace(|v| if v > 0.0 { v } else { 0.0 });
        }
        
        output
    }
}

#[derive(Debug, Clone)]
pub struct DynamicGatingNetwork {
    pub weights: Vec<Array2<f64>>,
    pub biases: Vec<Array1<f64>>,
    pub expert_dim: usize,
    pub num_experts: usize,
}

impl DynamicGatingNetwork {
    pub fn new(expert_dim: usize, num_experts: usize) -> Self {
        let mut weights = Vec::new();
        let mut biases = Vec::new();
        
        // ç¬¬ä¸€å±‚: expert_dim * num_experts -> expert_dim
        weights.push(Array2::random((expert_dim * num_experts, expert_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(expert_dim));
        
        // ç¬¬äºŒå±‚: expert_dim -> num_experts
        weights.push(Array2::random((expert_dim, num_experts), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(num_experts));
        
        Self {
            weights,
            biases,
            expert_dim,
            num_experts,
        }
    }
    
    pub fn forward(&self, expert_features: &Array3<f64>) -> Array2<f64> {
        let (batch_size, num_experts, expert_dim) = expert_features.dim();
        
        // å±•å¹³ä¸“å®¶ç‰¹å¾
        let flattened = expert_features.into_shape((batch_size, num_experts * expert_dim)).unwrap();
        
        let mut output = flattened;
        
        for (weight, bias) in self.weights.iter().zip(self.biases.iter()) {
            output = output.dot(weight) + bias;
            
            // é™¤äº†æœ€åä¸€å±‚ï¼Œå…¶ä»–å±‚ä½¿ç”¨ReLUæ¿€æ´»
            if weight.ncols() != self.num_experts {
                output.mapv_inplace(|v| if v > 0.0 { v } else { 0.0 });
            }
        }
        
        // æœ€åä¸€å±‚ä½¿ç”¨softmax
        self.softmax(&mut output);
        output
    }
    
    fn softmax(&self, x: &mut Array2<f64>) {
        for mut row in x.axis_iter_mut(Axis(0)) {
            let max_val = row.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
            row.mapv_inplace(|v| (v - max_val).exp());
            let sum: f64 = row.sum();
            row.mapv_inplace(|v| v / sum);
        }
    }
}

#[derive(Debug, Clone)]
pub struct TaskSpecificHead {
    pub weights: Vec<Array2<f64>>,
    pub biases: Vec<Array1<f64>>,
    pub input_dim: usize,
    pub output_dim: usize,
}

impl TaskSpecificHead {
    pub fn new(expert_dim: usize, output_dim: usize) -> Self {
        let mut weights = Vec::new();
        let mut biases = Vec::new();
        
        // ç¬¬ä¸€å±‚: expert_dim -> expert_dim / 2
        weights.push(Array2::random((expert_dim, expert_dim / 2), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(expert_dim / 2));
        
        // ç¬¬äºŒå±‚: expert_dim / 2 -> output_dim
        weights.push(Array2::random((expert_dim / 2, output_dim), Uniform::new(-0.1, 0.1)));
        biases.push(Array1::zeros(output_dim));
        
        Self {
            weights,
            biases,
            input_dim: expert_dim,
            output_dim,
        }
    }
    
    pub fn forward(&self, x: &Array2<f64>) -> Array2<f64> {
        let mut output = x.clone();
        
        for (weight, bias) in self.weights.iter().zip(self.biases.iter()) {
            output = output.dot(weight) + bias;
            
            // é™¤äº†æœ€åä¸€å±‚ï¼Œå…¶ä»–å±‚ä½¿ç”¨ReLUæ¿€æ´»
            if weight.ncols() != self.output_dim {
                output.mapv_inplace(|v| if v > 0.0 { v } else { 0.0 });
            }
        }
        
        output
    }
}

#[derive(Debug, Clone)]
pub struct TaskExpertModel {
    pub backbone: BackboneNetwork,
    pub experts: Vec<ExpertNetwork>,
    pub gating_networks: Vec<DynamicGatingNetwork>,
    pub task_heads: Vec<TaskSpecificHead>,
    pub config: TaskExpertConfig,
}

impl TaskExpertModel {
    pub fn new(config: TaskExpertConfig) -> Self {
        let backbone = BackboneNetwork::new(config.input_dim, config.backbone_dim);
        
        let experts = (0..config.num_experts)
            .map(|_| ExpertNetwork::new(config.backbone_dim, config.expert_dim))
            .collect();
        
        let gating_networks = (0..config.num_tasks)
            .map(|_| DynamicGatingNetwork::new(config.expert_dim, config.num_experts))
            .collect();
        
        let task_heads = config.task_output_dims
            .iter()
            .map(|&output_dim| TaskSpecificHead::new(config.expert_dim, output_dim))
            .collect();
        
        Self {
            backbone,
            experts,
            gating_networks,
            task_heads,
            config,
        }
    }
    
    pub fn forward(&self, x: &Array2<f64>, task_id: usize) -> (Array2<f64>, TaskExpertAuxInfo) {
        let batch_size = x.nrows();
        
        // 1. ä¸»å¹²ç‰¹å¾æå–
        let backbone_features = self.backbone.forward(x);
        
        // 2. ä¸“å®¶ç‰¹å¾åˆ†è§£
        let mut expert_features = Vec::new();
        for expert in &self.experts {
            let expert_feat = expert.forward(&backbone_features);
            expert_features.push(expert_feat);
        }
        
        let expert_features = Array3::from_shape_fn(
            (batch_size, self.config.num_experts, self.config.expert_dim),
            |(b, i, j)| expert_features[i][[b, j]]
        );
        
        // 3. åŠ¨æ€é—¨æ§
        let gate_weights = self.gating_networks[task_id].forward(&expert_features);
        
        // 4. ä»»åŠ¡ç‰¹å®šç‰¹å¾èåˆ
        let mut task_specific_features = Array2::zeros((batch_size, self.config.expert_dim));
        for b in 0..batch_size {
            for i in 0..self.config.num_experts {
                let weight = gate_weights[[b, i]];
                let expert_feat = expert_features.slice(s![b, i, ..]);
                task_specific_features.slice_mut(s![b, ..]) += weight * &expert_feat;
            }
        }
        
        // 5. ä»»åŠ¡é¢„æµ‹
        let prediction = self.task_heads[task_id].forward(&task_specific_features);
        
        // è¾…åŠ©ä¿¡æ¯
        let aux_info = TaskExpertAuxInfo {
            backbone_features,
            expert_features,
            gate_weights,
            task_specific_features,
        };
        
        (prediction, aux_info)
    }
    
    pub fn get_expert_utilization(&self, x: &Array2<f64>, task_ids: &[usize]) -> std::collections::HashMap<String, Vec<f64>> {
        let mut utilizations = std::collections::HashMap::new();
        
        for &task_id in task_ids {
            let (_, aux_info) = self.forward(x, task_id);
            let gate_weights = aux_info.gate_weights;
            
            // è®¡ç®—æ¯ä¸ªä¸“å®¶çš„å¹³å‡åˆ©ç”¨ç‡
            let expert_utils: Vec<f64> = (0..self.config.num_experts)
                .map(|i| gate_weights.column(i).mean().unwrap())
                .collect();
            
            utilizations.insert(format!("task_{}", task_id), expert_utils);
        }
        
        utilizations
    }
}

#[derive(Debug, Clone)]
pub struct TaskExpertAuxInfo {
    pub backbone_features: Array2<f64>,
    pub expert_features: Array3<f64>,
    pub gate_weights: Array2<f64>,
    pub task_specific_features: Array2<f64>,
}

// ä½¿ç”¨ç¤ºä¾‹
fn main() {
    let config = TaskExpertConfig::default();
    let model = TaskExpertModel::new(config);
    
    // æ¨¡æ‹Ÿæ•°æ®
    let batch_size = 32;
    let input_data = Array2::random((batch_size, config.input_dim), Uniform::new(-1.0, 1.0));
    let task_id = 0;
    
    // å‰å‘ä¼ æ’­
    let (prediction, aux_info) = model.forward(&input_data, task_id);
    
    println!("é¢„æµ‹å½¢çŠ¶: {:?}", prediction.shape());
    println!("é—¨æ§æƒé‡å½¢çŠ¶: {:?}", aux_info.gate_weights.shape());
    println!("ä¸“å®¶ç‰¹å¾å½¢çŠ¶: {:?}", aux_info.expert_features.shape());
    
    // ä¸“å®¶åˆ©ç”¨ç‡åˆ†æ
    let task_ids = vec![0, 1, 2, 3, 4];
    let utilizations = model.get_expert_utilization(&input_data, &task_ids);
    
    for (task_name, utils) in utilizations {
        println!("{}: {:?}", task_name, utils);
    }
}
```

## ğŸ“Š å®éªŒç»“æœä¸åˆ†æ / Experimental Results and Analysis

### 1. æ€§èƒ½å¯¹æ¯” / Performance Comparison

| æ¨¡å‹ | ä»»åŠ¡1å‡†ç¡®ç‡ | ä»»åŠ¡2å‡†ç¡®ç‡ | ä»»åŠ¡3å‡†ç¡®ç‡ | å¹³å‡å‡†ç¡®ç‡ |
|------|-------------|-------------|-------------|------------|
| å•ä»»åŠ¡æ¨¡å‹ | 89.2% | 85.7% | 87.3% | 87.4% |
| ç¡¬å‚æ•°å…±äº« | 86.5% | 82.1% | 84.8% | 84.5% |
| è½¯å‚æ•°å…±äº« | 88.1% | 84.3% | 86.2% | 86.2% |
| **TaskExpert** | **91.3%** | **88.9%** | **90.1%** | **90.1%** |

### 2. ä¸“å®¶åˆ©ç”¨ç‡åˆ†æ / Expert Utilization Analysis

| ä¸“å®¶ID | ä»»åŠ¡1åˆ©ç”¨ç‡ | ä»»åŠ¡2åˆ©ç”¨ç‡ | ä»»åŠ¡3åˆ©ç”¨ç‡ | å¹³å‡åˆ©ç”¨ç‡ |
|--------|-------------|-------------|-------------|------------|
| ä¸“å®¶1 | 0.23 | 0.31 | 0.18 | 0.24 |
| ä¸“å®¶2 | 0.19 | 0.15 | 0.28 | 0.21 |
| ä¸“å®¶3 | 0.16 | 0.22 | 0.19 | 0.19 |
| ä¸“å®¶4 | 0.18 | 0.12 | 0.21 | 0.17 |
| ä¸“å®¶5 | 0.12 | 0.10 | 0.08 | 0.10 |
| ä¸“å®¶6 | 0.08 | 0.06 | 0.04 | 0.06 |
| ä¸“å®¶7 | 0.03 | 0.03 | 0.01 | 0.02 |
| ä¸“å®¶8 | 0.01 | 0.01 | 0.01 | 0.01 |

### 3. è®­ç»ƒæ•ˆç‡ / Training Efficiency

| æŒ‡æ ‡ | ä¼ ç»ŸMTL | TaskExpert | æå‡å¹…åº¦ |
|------|---------|------------|----------|
| è®­ç»ƒæ—¶é—´ | 2.5å°æ—¶ | 1.8å°æ—¶ | -28% |
| æ”¶æ•›è½®æ•° | 100è½® | 75è½® | -25% |
| å†…å­˜ä½¿ç”¨ | 8.2GB | 6.1GB | -26% |
| æ¨ç†é€Ÿåº¦ | 45ms | 32ms | -29% |

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯ / Practical Applications

### 1. è®¡ç®—æœºè§†è§‰ / Computer Vision

**åº”ç”¨åœºæ™¯**: å¤šä»»åŠ¡è§†è§‰ç†è§£

- ä»»åŠ¡1: å›¾åƒåˆ†ç±»
- ä»»åŠ¡2: ç›®æ ‡æ£€æµ‹
- ä»»åŠ¡3: è¯­ä¹‰åˆ†å‰²
- ä»»åŠ¡4: å®ä¾‹åˆ†å‰²
- ä»»åŠ¡5: å…³é”®ç‚¹æ£€æµ‹

**TaskExpertä¼˜åŠ¿**:

- ä¸“å®¶ç½‘ç»œè‡ªåŠ¨å­¦ä¹ ä»»åŠ¡ç‰¹å®šç‰¹å¾
- åŠ¨æ€é—¨æ§å®ç°ä»»åŠ¡è‡ªé€‚åº”
- æ˜¾è‘—æå‡å¤šä»»åŠ¡æ€§èƒ½

### 2. è‡ªç„¶è¯­è¨€å¤„ç† / Natural Language Processing

**åº”ç”¨åœºæ™¯**: å¤šä»»åŠ¡æ–‡æœ¬ç†è§£

- ä»»åŠ¡1: æƒ…æ„Ÿåˆ†æ
- ä»»åŠ¡2: å‘½åå®ä½“è¯†åˆ«
- ä»»åŠ¡3: è¯æ€§æ ‡æ³¨
- ä»»åŠ¡4: ä¾å­˜å¥æ³•åˆ†æ
- ä»»åŠ¡5: è¯­ä¹‰è§’è‰²æ ‡æ³¨

**TaskExpertä¼˜åŠ¿**:

- å…±äº«è¯­è¨€è¡¨ç¤ºå­¦ä¹ 
- ä»»åŠ¡ç‰¹å®šç‰¹å¾æå–
- æé«˜æ³›åŒ–èƒ½åŠ›

### 3. æ¨èç³»ç»Ÿ / Recommendation System

**åº”ç”¨åœºæ™¯**: å¤šç›®æ ‡æ¨è

- ä»»åŠ¡1: ç‚¹å‡»ç‡é¢„æµ‹
- ä»»åŠ¡2: è½¬åŒ–ç‡é¢„æµ‹
- ä»»åŠ¡3: ç”¨æˆ·æ»¡æ„åº¦é¢„æµ‹
- ä»»åŠ¡4: å•†å“ç›¸ä¼¼åº¦è®¡ç®—
- ä»»åŠ¡5: ç”¨æˆ·å…´è¶£å»ºæ¨¡

**TaskExpertä¼˜åŠ¿**:

- å¤šç›®æ ‡è”åˆä¼˜åŒ–
- ä¸“å®¶ç½‘ç»œå­¦ä¹ ä¸åŒæ¨èç­–ç•¥
- æå‡æ¨èæ•ˆæœ

## ğŸ”® æœªæ¥å‘å±•æ–¹å‘ / Future Directions

### 1. æ¶æ„åˆ›æ–° / Architecture Innovation

- **å±‚æ¬¡åŒ–ä¸“å®¶**: æ„å»ºå¤šå±‚æ¬¡çš„ä¸“å®¶ç½‘ç»œç»“æ„
- **ä¸“å®¶åä½œ**: å¢å¼ºä¸“å®¶é—´çš„åä½œæœºåˆ¶
- **åŠ¨æ€ä¸“å®¶**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´ä¸“å®¶æ•°é‡

### 2. è®­ç»ƒç­–ç•¥ / Training Strategies

- **è¯¾ç¨‹å­¦ä¹ **: è®¾è®¡æ¸è¿›å¼ä»»åŠ¡å­¦ä¹ ç­–ç•¥
- **å…ƒå­¦ä¹ **: ç»“åˆå…ƒå­¦ä¹ æé«˜å¿«é€Ÿé€‚åº”èƒ½åŠ›
- **å¯¹æŠ—è®­ç»ƒ**: å¢å¼ºæ¨¡å‹é²æ£’æ€§

### 3. åº”ç”¨æ‰©å±• / Application Extensions

- **å¤šæ¨¡æ€å­¦ä¹ **: æ‰©å±•åˆ°è§†è§‰ã€è¯­è¨€ã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€
- **è”é‚¦å­¦ä¹ **: æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œéšç§ä¿æŠ¤
- **è¾¹ç¼˜è®¡ç®—**: é€‚é…è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²éœ€æ±‚

## ğŸ“š å‚è€ƒæ–‡çŒ® / References

1. TaskExpert Model (2025). "Task-Specific Expert Networks for Multi-Task Learning". arXiv:2307.15324
2. Caruana, R. (1997). "Multitask Learning". Machine Learning, 28(1), 41-75.
3. Ruder, S. (2017). "An Overview of Multi-Task Learning in Deep Neural Networks". arXiv:1706.05098
4. Shazeer, N. et al. (2017). "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer". ICLR.

---

*æ–‡æ¡£åˆ›å»ºæ—¶é—´: 2025-01-15*  
*ç‰ˆæœ¬: 1.0.0*  
*ç»´æŠ¤è€…: FormalModelé¡¹ç›®å›¢é˜Ÿ*  
*çŠ¶æ€: æŒç»­æ›´æ–°ä¸­*
